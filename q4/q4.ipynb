{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Augmentation Techniques from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HSL Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rgb_to_hsl(r, g, b):\n",
        "    r, g, b = r / 255.0, g / 255.0, b / 255.0\n",
        "    max_c = np.maximum(np.maximum(r, g), b)\n",
        "    min_c = np.minimum(np.minimum(r, g), b)\n",
        "    lightness = (max_c + min_c) / 2.0\n",
        "\n",
        "    saturation = np.zeros_like(lightness)\n",
        "    hue = np.zeros_like(lightness)\n",
        "\n",
        "    mask = max_c != min_c\n",
        "    dif = max_c - min_c\n",
        "    saturation[mask] = np.where(lightness[mask] > 0.5, dif[mask] / (2.0 - max_c[mask] - min_c[mask]), dif[mask] / (max_c[mask] + min_c[mask]))\n",
        "\n",
        "    mask_r = (max_c == r) & mask\n",
        "    mask_g = (max_c == g) & mask\n",
        "    mask_b = (max_c == b) & mask\n",
        "\n",
        "    hue[mask_r] = ((g[mask_r] - b[mask_r]) / dif[mask_r] + (g[mask_r] < b[mask_r]) * 6) % 6\n",
        "    hue[mask_g] = ((b[mask_g] - r[mask_g]) / dif[mask_g] + 2) % 6\n",
        "    hue[mask_b] = ((r[mask_b] - g[mask_b]) / dif[mask_b] + 4) % 6\n",
        "    hue /= 6\n",
        "\n",
        "    return hue, saturation, lightness\n",
        "\n",
        "def hsl_to_rgb(hue, saturation, lightness):\n",
        "    def hue_to_rgb(p, q, t):\n",
        "        t = np.where(t < 0, t + 1, t)\n",
        "        t = np.where(t > 1, t - 1, t)\n",
        "        return np.where(t < 1 / 6, p + (q - p) * 6 * t, \n",
        "                        np.where(t < 1 / 2, q,\n",
        "                                 np.where(t < 2 / 3, p + (q - p) * (2 / 3 - t) * 6, p)))\n",
        "\n",
        "    q = np.where(lightness < 0.5, lightness * (1 + saturation), lightness + saturation - lightness * saturation)\n",
        "    p = 2 * lightness - q\n",
        "    r = hue_to_rgb(p, q, hue + 1 / 3)\n",
        "    g = hue_to_rgb(p, q, hue)\n",
        "    b = hue_to_rgb(p, q, hue - 1 / 3)\n",
        "    return (r * 255).astype(np.uint8), (g * 255).astype(np.uint8), (b * 255).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saturation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "def adjust_saturation(image, saturation_factor):\n",
        "    r, g, b = image[..., 0], image[..., 1], image[..., 2]\n",
        "    hue, saturation, lightness = rgb_to_hsl(r, g, b)\n",
        "    saturation *= saturation_factor\n",
        "    saturation = np.clip(saturation, 0, 1)\n",
        "\n",
        "    r, g, b = hsl_to_rgb(hue, saturation, lightness)\n",
        "    new_pixels = np.stack([r, g, b], axis=-1)\n",
        "\n",
        "    new_image = Image.fromarray(new_pixels, 'RGB')\n",
        "    return new_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Contrast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        " \n",
        "def adjust_contrast(pixels, factor):\n",
        "    mean = np.mean(pixels)\n",
        "    \n",
        "    new_pixels = mean + (pixels - mean) * factor\n",
        "    new_pixels = np.clip(new_pixels, 0, 255)\n",
        "    \n",
        "    new_pixels = new_pixels.astype(np.uint8)\n",
        "    \n",
        "    new_image = Image.fromarray(new_pixels)\n",
        "    return new_image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Brightness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "def adjust_brightness(image, brightness_factor):\n",
        "    r, g, b = image[..., 0], image[..., 1], image[..., 2]\n",
        "    hue, saturation, lightness = rgb_to_hsl(r, g, b)\n",
        "    lightness *= brightness_factor\n",
        "    lightness = np.clip(lightness, 0, 1)\n",
        "\n",
        "    r, g, b = hsl_to_rgb(hue, saturation, lightness)\n",
        "    new_pixels = np.stack([r, g, b], axis=-1)\n",
        "\n",
        "    new_image = Image.fromarray(new_pixels, 'RGB')\n",
        "    return new_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Flipping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flip_image(image, flip_type='horizontal'):\n",
        "    if flip_type == 'horizontal':\n",
        "        flipped_pixels = np.fliplr(image)\n",
        "    elif flip_type == 'vertical':\n",
        "        flipped_pixels = np.flipud(image)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid flip_type. Choose from 'horizontal' or 'vertical'.\")\n",
        "    \n",
        "    flipped_image = Image.fromarray(flipped_pixels)\n",
        "    return flipped_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rotate_image(pixels, angle):\n",
        "    angle_rad = np.deg2rad(angle)\n",
        "    \n",
        "    original_height, original_width, _ = pixels.shape\n",
        "\n",
        "    center_x, center_y = original_width // 2, original_height // 2\n",
        "    \n",
        "    y_indices, x_indices = np.meshgrid(np.arange(original_height), np.arange(original_width), indexing='ij')\n",
        "    \n",
        "    x_indices_flat = x_indices.flatten()\n",
        "    y_indices_flat = y_indices.flatten()\n",
        "    \n",
        "    relative_x = x_indices_flat - center_x\n",
        "    relative_y = y_indices_flat - center_y\n",
        "    \n",
        "    orig_x_flat = (relative_x * np.cos(angle_rad) + relative_y * np.sin(angle_rad)).astype(int) + center_x\n",
        "    orig_y_flat = (-relative_x * np.sin(angle_rad) + relative_y * np.cos(angle_rad)).astype(int) + center_y\n",
        "    valid_mask = (orig_x_flat >= 0) & (orig_x_flat < original_width) & (orig_y_flat >= 0) & (orig_y_flat < original_height)\n",
        "    \n",
        "    rotated_image = np.zeros_like(pixels)\n",
        "    rotated_image[y_indices_flat[valid_mask], x_indices_flat[valid_mask]] = pixels[orig_y_flat[valid_mask], orig_x_flat[valid_mask]]\n",
        "    \n",
        "    new_image = Image.fromarray(rotated_image)\n",
        "\n",
        "    return new_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "def translate_image(pixels, tx, ty):\n",
        "    original_height, original_width, _ = pixels.shape\n",
        "\n",
        "    translated_image = np.zeros_like(pixels)\n",
        "\n",
        "    y_indices, x_indices = np.meshgrid(np.arange(original_height), np.arange(original_width), indexing='ij')\n",
        "\n",
        "    translated_x = x_indices - tx\n",
        "    translated_y = y_indices - ty\n",
        "\n",
        "    valid_mask = (translated_x >= 0) & (translated_x < original_width) & (translated_y >= 0) & (translated_y < original_height)\n",
        "\n",
        "    translated_image[y_indices[valid_mask], x_indices[valid_mask]] = pixels[translated_y[valid_mask], translated_x[valid_mask]]\n",
        "    new_image = Image.fromarray(translated_image)\n",
        "\n",
        "    return new_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Applying Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_image(image, original_name, suffix, output_dir):\n",
        "    base_name, ext = os.path.splitext(original_name)\n",
        "    new_name = f\"{base_name}_{suffix}{ext}\"\n",
        "    image.save(os.path.join(output_dir, new_name))\n",
        "\n",
        "input_dir = '../images'\n",
        "output_dir = 'augmented_images'\n",
        "\n",
        "image_files = [f for f in os.listdir(input_dir) if f.endswith(('.jpeg'))]\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(input_dir, image_file)\n",
        "    image = Image.open(image_path)\n",
        "    pixels = np.array(image)\n",
        "    transformed_images = {}\n",
        "\n",
        "    # Transformations\n",
        "    transformed_images['saturation_0.5'] = adjust_saturation(pixels, 0.5)\n",
        "    transformed_images['saturation_1.5'] = adjust_saturation(pixels, 1.5)\n",
        "    transformed_images['flipped_horizontal'] = flip_image(pixels, 'horizontal')\n",
        "    transformed_images['flipped_vertical'] = flip_image(pixels, 'vertical')\n",
        "    transformed_images['contrast_0.5'] = adjust_contrast(pixels, 0.5)\n",
        "    transformed_images['contrast_2.0'] = adjust_contrast(pixels, 2.0)\n",
        "    transformed_images['translated_10_20'] = translate_image(pixels, 10, 20)\n",
        "    transformed_images['translated_30_50'] = translate_image(pixels, 30, 50)\n",
        "    transformed_images['brightness_0.5'] = adjust_brightness(pixels, 0.5)\n",
        "    transformed_images['brightness_2.0'] = adjust_brightness(pixels, 2.0)\n",
        "    transformed_images['rotated_90'] = rotate_image(pixels, 90)\n",
        "    transformed_images['rotated_180'] = rotate_image(pixels, 180)\n",
        "\n",
        "    for suffix, img in transformed_images.items():\n",
        "        save_image(img, image_file, suffix, output_dir)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
